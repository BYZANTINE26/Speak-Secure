{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Could not import the PyAudio C module 'pyaudio._portaudio'.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/yuvraj/opt/anaconda3/envs/voice/lib/python3.11/site-packages/pyaudio/_portaudio.cpython-311-darwin.so, 0x0002): symbol not found in flat namespace '_PaMacCore_SetupChannelMap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocessing\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyaudio\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwave\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/voice/lib/python3.11/site-packages/pyaudio/__init__.py:111\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyaudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_portaudio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpa\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCould not import the PyAudio C module \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyaudio._portaudio\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/yuvraj/opt/anaconda3/envs/voice/lib/python3.11/site-packages/pyaudio/_portaudio.cpython-311-darwin.so, 0x0002): symbol not found in flat namespace '_PaMacCore_SetupChannelMap'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import python_speech_features as mfcc\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pyaudio\n",
    "import time\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and return the delta of given feature vector matrix\n",
    "\n",
    "def calculate_delta(array):\n",
    "    N = 2\n",
    "    rows, cols = array.shape\n",
    "\n",
    "    # Create an array of indices for the sliding window\n",
    "    indices = np.arange(-N, N + 1)\n",
    "    \n",
    "    # Ensure the indices stay within bounds\n",
    "    indices = np.clip(indices + np.arange(rows)[:, np.newaxis], 0, rows - 1)\n",
    "\n",
    "    # Calculate the delta using array slicing and operations\n",
    "    left_neighbors = array[indices[:, N - 1]]\n",
    "    right_neighbors = array[indices[:, N + 1]]\n",
    "    delta = (right_neighbors - left_neighbors) + 2 * (right_neighbors - 2 * array[indices[:, N]] + left_neighbors)\n",
    "    delta /= 10\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert audio to mfcc features\n",
    "\n",
    "def extract_features(audio, rate):\n",
    "    mfcc_features = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, appendEnergy=True, nfft=1103)\n",
    "    mfcc_features = preprocessing.scale(mfcc_features)\n",
    "    delta = calculate_delta(mfcc_features)\n",
    "    combined = np.hstack((mfcc_features, delta))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user():\n",
    "    name = input(\"Enter your username: \")\n",
    "    if os.path.exists('./voice_database/' + name):\n",
    "        print(\"User already exists \\n Try again with another username\")\n",
    "        return\n",
    "    \n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 3 # TODO: 5\n",
    "\n",
    "    source = \"./voice_database/\" + name\n",
    "    os.mkdir(source)\n",
    "    for i in range(3):\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        if i == 0:\n",
    "            j = 3\n",
    "            while j>=0:\n",
    "                time.sleep(1.0)\n",
    "                print(\"Speak your name in {} seconds\".format(j))\n",
    "                clear_output(wait = True)\n",
    "                j -= 1\n",
    "        \n",
    "        elif i == 1:\n",
    "            print(\"Speak your name one more time\")\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        else:\n",
    "            print(\"Speak your name one last time\")\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # start Recording\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "        print(\"recording...\")\n",
    "        frames = []\n",
    "\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "        \n",
    "        # stop Recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "        # saving wav file of speaker\n",
    "        waveFile = wave.open(source + '/' + str((i+1)) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        print(\"Done\")\n",
    "\n",
    "    dest =  \"./gmm_models/\"\n",
    "    count = 1\n",
    "\n",
    "    for path in os.listdir(source):\n",
    "        path = os.path.join(source, path)\n",
    "\n",
    "        features = np.array([])\n",
    "\n",
    "        # reading audio files of speaker\n",
    "        (sr, audio) = read(path)\n",
    "\n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector = extract_features(audio,sr)\n",
    "\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "\n",
    "        # when features of 3 files of speaker are concatenated, then do model training\n",
    "        if count == 3:\n",
    "            gmm = GMM(n_components = 16, max_iter = 200, covariance_type='diag', n_init = 3)\n",
    "            gmm.fit(features)\n",
    "\n",
    "            # saving the trained gaussian model\n",
    "            pickle.dump(gmm, open(dest + name + '.gmm', 'wb'))\n",
    "            print(name + ' added successfully')\n",
    "\n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_user():\n",
    "    name = input(\"Enter the name of the user you want to delete: \") # TODO: check if user exists\n",
    "    [os.remove(path) for path in glob.glob('./voice_database/' + name + '/*')]\n",
    "    os.rmdir('./voice_database/' + name)\n",
    "    os.remove('./gmm_models/' + name + '.gmm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voice Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize():\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 3\n",
    "    FILENAME = \"./test.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file\n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    modelpath = \"./gmm_models/\"\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    # # Find the GMM model for the target username\n",
    "    # target_model = None\n",
    "    # for fname in gmm_files:\n",
    "    #     speaker = fname.split(\"/\")[-1].split(\".gmm\")[0]\n",
    "    #     if speaker == target_username:\n",
    "    #         target_model = pickle.load(open(fname, 'rb'))\n",
    "    #         break\n",
    "\n",
    "    # if target_model is None:\n",
    "    #     print(\"User not found in the database!\")\n",
    "    #     return\n",
    "\n",
    "    # # Read test file\n",
    "    # sr, audio = read(FILENAME)\n",
    "\n",
    "    # # Extract MFCC features\n",
    "    # vector = extract_features(audio, sr)\n",
    "    # log_likelihood = target_model.score(vector)  # Calculate the log-likelihood for the target model\n",
    "\n",
    "    # if log_likelihood > some_threshold:  # Set an appropriate threshold for recognition\n",
    "    #     print(f\"Recognized as {target_username}\")\n",
    "    # else:\n",
    "    #     print(\"Not Recognized! Try again...\")\n",
    "\n",
    "    models = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "    speakers = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname in gmm_files]\n",
    "\n",
    "    if len(models) == 0:\n",
    "        print(\"No Users in the Database!\")\n",
    "        return\n",
    "    \n",
    "    #read test file\n",
    "    sr,audio = read(FILENAME)\n",
    "\n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models))\n",
    "\n",
    "    #checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]         \n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    pred = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred]\n",
    "\n",
    "    # if voice not recognized than terminate the process\n",
    "    if identity == 'unknown':\n",
    "        print(\"Not Recognized! Try again...\")\n",
    "        return\n",
    "    else:\n",
    "        print( \"Recognized as - \", identity)\n",
    "        return identity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice",
   "language": "python",
   "name": "voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
